{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIDDEN MARKOV MODEL\n",
    "\n",
    "(Rabiner & Juang, 1993)\n",
    "\n",
    "### Formulation\n",
    "\n",
    "*Consider a first order N-state Markov chain as illustrated for N=3 in the figure below.  The system can be described in one of N distinct states at any discrete time instant t.* A variable $q_t$ can be used as the state of the system at time t. *The Markov chain is then described by a state transition probabilty matrix A=$a_{ij}$, where\n",
    "$$ a_{ij}=Pr(q_t=j|g_{t-1}=i),\\text{ } 1 \\le i, j \\le N - - - - \\dots(1)$$\n",
    "with the following axiomatic constraints\n",
    "$$ a_{ij} \\ge 0 - - - - \\dots(2)$$\n",
    "and\n",
    "$$ \\sum_{j=1}^Na_{ij}=1\\text{ for all i} - - - - -\\dots(3) $$\n",
    "\n",
    "*Note that equation (1) we have assumed homogeneity of the Markov chain so that the transition probabilities do not depend on time.  Assume that t=0 the state of the system is $q_0$ is specified by an initial state probability $\\pi_i=Pr(q_0,q_1,q_2,\\dots q_T)$, the probability of q being generated by the Markov chain is*\n",
    "$$ Pr(q|A,\\pi)=\\pi_{q_0}a_{q_0q_1}a_{q_1q_2}\\dots a_{q_{T-1}q_T} - - - -\\dots(4)$$\n",
    "![Figure 1](https://selene.hud.ac.uk/u1273400/images/seg_media/hmm1.PNG)\n",
    "**Figure 1:** A First-Order Three-State Markov Chain With Associated Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Suppose now that the state sequence q cannot be readily observed.  Instead, we envision each observation $O_t$, say a cepstral vetor as mentioned previously, as being produced with the system in state $q_t, q_1\\in{1,2,\\dots,N}$.  We assume that the production of $O_t$ in each possible state i(i=1,2,\\dots,N) is stochastic and characterised by a set of observation probability measures $B =  \\{b_i(O_t)\\}_{i=1}^N,$ *\n",
    "where\n",
    "$$ b_i(O_t)=Pr(O_t|q_t=i) - - - -\\dots(5)$$\n",
    "\n",
    "*If the state sequence q that led to the observation sequence O=(O_1, O_2,\\dots, O_T) is known, the probability of O being generated by the system is assumed to be*\n",
    "$$ Pr(O|q,B)=b_{q_1}(O_1)b_{q_2}(O_2)\\dots b_{q_T}(O_T) - - - - \\dots(6)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The joint probaility of O and q being produced by the system is simply the product of (4) and (6), written as*\n",
    "$$ Pr(O,q|\\pi,A,B)=\\pi_{q_0}\\prod_{t=1}^Ta_{q_{t-1}q_t}b_{q_t}(O_t) - - - - \\dots(7) $$\n",
    "*It then follows that the stochastic process, represented by the observation sequence O, is characterised by*\n",
    "$$\\begin{aligned}Pr(O|\\pi,A,B)&=\\sum_qPr(O,q|\\pi,A,B)\\\\&=\\sum_q\\pi_{q_0}\\prod_{t=1}^Ta_{q_{t-1}q_t}b_{q_t}(O_t) - - - - \\dots(8) \\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*which describes the probability of O being produced by a system without assuming the knowledge of the state sequence in which it was generated.  The triple $\\lambda=(\\pi, A, B)$ thus defines a HMM in equation (8).  In the following, we shall refer to $\\lambda$ as the model and the model parameter set interchangeabley without ambiguity.*\n",
    "\n",
    "*In terms of physical process of a speech signal, one interpretation that may be helpful for initial understanding of the problem is that a state represent an abstract speech code (such as a phoneme) embedded ina sequence of spectral observation, and because speech is normally produced in a continuous manner, it is often difficult and sometimes unnecessary to determine how and when a state transition (from one abstract speech code to another) is made.  Therefore in equation (8) we do not assume explicit, definitive observation of the state sequence q, although the Markovian structure of the state sequence is strictly implied.  This is why it is called a \"hidden\" Markov Model.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Statistical Method of HMM\n",
    "*\n",
    "In the development of the HMM methodology, the following problems are of particular interest.  First given the observation sequence O and a model $\\lambda$, how do we efficiently evaluate the probability of O being produced by the source model $\\lambda$, how do we efficiently evaluate the probability of O being produced by the source model $\\lambda$ - that is, Pr(O| $\\lambda$)? Secondly, given the observation O, how do we solve the invise problem of estimating parameters in  $\\lambda$?  Although the probability measure of equation (8) does not depend explicitly on q, the knowledge of the most likely state sequence q that led to the observation O is desirable in many applications.  The third problem then is how to deduce from O the most likely state sequence q in a meaningful manner.  According to convention \n",
    "(Ferguson, 1980) we call these three problems (1) the evaluation problem, (2) the estimation problem, and (3) the decoding problem.  In the following sections, we describe several conventional solutions to these three standard problems.\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Evaluation problem\n",
    "*\n",
    "The main concern in the evaluation problem is computational efficiency.  Without complexity constraints, one can simply evaluate Pr(O|$\\lambda$) directly from the definition equation (8).  Since the summation in (8) involved $N^{T+1}$ possible q sequences, the total computational requirements are on the order of $2T.N^{T+1}$ operations.  The need to compute equation (8) without the exponential growth of computation, as a function of the sequence length T, is the first challenge for implementation of the HMM technique.  Fortunately, using the well-known forward-backward procedure (Baum, 1972), this exorbitant computation requirement of the direct summation can be easily alleviated.\n",
    "*\n",
    "\n",
    "*A forward induction procedure allows evaluation of the probability Pr(O|$\\lambda$) to be carried out with only computational requirement linear in the sequence length T and quadratic in the number of states N.  To see how this is done, let us define the forward variable $\\alpha_t(i)$ as $\\alpha_t(i)=Pr(O_1,O_2,\\dots,O_t,q_t=i|\\lambda)$ - that is, the probability of the partial observation sequence up to time t and state $q_t=i$ at time t.  With reference to figure 2, which shows a tresllis structure implementation of the computation of $\\alpha_(i)$, we see that the forward variable can be calculated inductively by*\n",
    "$$ \\alpha_t(j)=\\left[\\sum_{t=1}^N\\alpha_{t-1}(i)a_{ij}\\right]b_j(O_t) $$\n",
    "\n",
    "*The desired result is simply $Pr(O|\\lambda)=\\sum_{t=1}^N\\alpha_T(i)$.*\n",
    "![figure 2](http://selene.hud.ac.uk/u1273400/images/seg_media/hmm2.PNG)\n",
    "**Figure 2:** Trellis structure for the calculation of the forward partial probabilities.\n",
    "\n",
    "*This temendous reduction in computation makes HMM method attractive and viable for speech recognizer designs because the evaluation problem can be viewed as one of scoring how well an unknown observation sequence (corresponding to the speech to be recognized) matches a given model (or sequence of models) source, thus providing and efficient mechanism for classification.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Estimation Problem\n",
    "\n",
    "*Given an observation sequence (or a set of sequences) O, the estimation problem involves finding the \"right\" model parameter values that specify a model most likely to produce the given sequence.  In speech recognition, this is often called \"training\", and the given sequence, on the basis of which we obtain the model parameters, this is called the training sequence, even though the formulation here is statistical.*\n",
    "\n",
    "*In solving the estimation problem, we often follow the method of maximum likelihood (ML); that is, we choose $\\lambda$ such that $Pr(O|\\lambda)$, as defined by equation (8), is maximized for the given training sequence O.  The Baum-Welch algorithm (often blended with the forward-backward algorithm because of its interpretation as an extension of the forward induction procedure to the evaluation problem) cleverly accomplishes this maximisation objective in a two-step procedure.  Based on the existing model $\\lambda'$ (possibly obtained randomly), the first step transforms the objective function $Pr(O|\\lambda) into a new function $Q(\\lambda',\\lambda)$ that essentially measures a divergence between the initial model $\\lambda'$ and an updated model $\\lambda$. The Q function is defined, for the simplest case, as*\n",
    "\n",
    "$$ Q(\\lambda',\\lambda)=\\sum_qPr(O,q|\\lambda')log Pr(O,q|\\lambda) - - - - \\dots(9)$$\n",
    "\n",
    "*where $Pr(O,q|\\lambda)$ is given in equation (7).  Because $Q(\\lambda',\\lambda)\\ge Q(\\lambda',\\lambda')$ implies $Pr(O|\\lambda)\\ge Pr(O|\\lambda')$, we can then simply maximise the function $Q(\\lambda',\\lambda)$ over $\\lambda$ to improve $\\lambda'$ in the sense of increasing the likelihood $Pr(O|\\lambda)$.  The maximisation of the Q function over $\\lambda$ is the second step of the algoirhtm.  The algorithm continuses by replacing $\\lambda'$ with $\\lambda$ and repeating the two steps until some stopping criterion is met.  the Algorithm is of a general hill-climbing type and is only guaranteed to produce fixed-point solutions, although in practice the lack of global optimality does not seem to cause serious problems in recognition performance.    The Q function of equation (9) is clearly an expectation operation so the two-step algorithm is identical to the Expectation-Maximisation (EM) algorithm \n",
    "(Dempster et al., 1977).*  Another more effective method for way to solve this problem is the ML algorithm discussed in a later section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Decoding Problem\n",
    "*\n",
    "As noted previously, we often are interested in uncovering the most likely state sequence that led to the observation sequence O.  Although the probability measure of an HMM, by definition does not involve the state sequence, it is important in many applications to have the knowledge of the most likely state sequence for several reasons.  As an example, if we use the states of a word model to represent the distinct sounds in the word, it may be desirable to know the correspondence between the speech segments and the sounds of the word, because the duration of the individual speech segments provides useful information for speech recognition.*\n",
    "\n",
    "*As with the second problem, there are several ways to define the decoding objective.   The most trivial choice is, following the Bayesian framework, to maximize the (instantaneous) a posteriori probability*\n",
    "\n",
    "$$\\gamma_t(i)=Pr(q_t=i|O,\\lambda) - - - - \\dots(10) $$\n",
    "\n",
    "*that is, we decode the state at time t by choosing $\\bar{q}_t$ to be*\n",
    "$$\\bar{q}_t=arg max_{1\\le i \\le N}\\gamma_t(i) - - - -\\dots(11) $$\n",
    "\n",
    "*It is also possible to extend the definition of equation (10) to the cases of pairs of states or triples of states and so on.  For example, the rule*\n",
    "\n",
    "$$(\\bar{q}_t,\\bar{q}_{t+1})=arg max_{1\\le i \\le N} Pr(q_t=i,q_{t+1}=j|O,\\lambda) - - - - \\dots(12) $$\n",
    "*will produce the maximum a posteriori (MAP) result of the minimum number of incorrectly decoded state pairs, given the observation sequence O.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Although the preceeding discussion shows the flexibility of localized decoding, we often choose to work on the entire state sequence q by maximising $Pr(q|O,\\lambda)$ for three reasons: (1) It is optimal for the unknown observation O in the MAP senese, (2) speech utterances are ususally not prohibitively long so as to require locally (rather than globally) optimal decoding, and (3) it is possible to formulate the maximisation of $Pr(q|O,\\lambda)$ in a sequential manner to be solved by dynamic programming methods such as the Viterbi algorithm*.\n",
    "\n",
    "*Maximisation of $Pr(q|O,\\lambda)$ is equivalent to maximisation of $Pr(q,O|\\lambda)$ because $Pr(O|\\lambda)$ is not involved* in both maximisation processes. *From equation (7) we see that\n",
    "\n",
    "$$ \\begin{aligned} & Pr(q_1,q_2,\\dots,q_t,O_1,O_2,\\dots,O_t|\\lambda)\\\\\n",
    "&= Pr(q_1,q_2,\\dots,q_{t-1},O_1,O_2,\\dots,O_{t-1}|\\lambda).a_{q_{t-1}q_t}(O_t) - - - -\\dots(13)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we define*\n",
    "$$\\begin{aligned} \\delta_t(i)\n",
    "\\end{aligned}$$\n",
    "*then the followin recursion is also true*\n",
    "$$ \\delta_{t+1}(j)=[max_t \\delta_t(i)a_{ij}]b_j(O_{t+1}) - - - - \\dots (15)$$\n",
    "\n",
    "*The optimal state sequence is thus the one that leads to $\\delta_T(\\bar(q)_T)=max_i\\delta_T(i)$.  This recursion is in a form suitable for application of the Viterbi algorithm.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech Recognition using HMMs\n",
    "*\n",
    "The typical use of HMMs in speech recogntion is not very differnt from traditional pattern matching paradigm.  Successful application of HMM methods usually involve the following steps*\n",
    "\n",
    "1. *Define a set of L sounds classes for modeling, such as phonemes or words; call thesee sound classes $V=\\{v_1,v_2,\\dots,v_L\\}.$*\n",
    "2. *For each class, collect a sizable set (the training set) of labeled utterances that are known to be in the class.*\n",
    "3. *Based on each training set, solve the estimation problem to obtain a \"best\" model $\\lambda_i$ for each class $v_i(i=1,2,\\dots,L)$*.\n",
    "4. *During recognition, evaluat $Pr(O|\\lambda_i)(i=1,2,\\dots,L)$ for the unknown utterance O and identify the speech that produced O as class $v_j$ if*\n",
    "$$Pr(O|\\lambda_j)=max_{1\\le i\\le L}Pr(O|\\lambda_i) - - - -\\dots(16)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hmm Methodology\n",
    "\n",
    "*The foundation of the HMM methodology is built on the well-established field of statistics and probability theory.  That is to say, the development of the methodology follows a tractable mathematical structure that can be examined and studied analytically.*\n",
    "\n",
    "*The basic theoretical strength of the HMM is that it combines modeling of stationary stochastic processes (for the short-time spectra) and the temporla relationship among the processes (via a Markov chain) together in a well-defined probability space.  The measure of such a probabilit space is defined by equation (8).  This combination allows us to study these two separate aspects of modeling a dynamic process (like speech) using one consistent framework.*\n",
    "\n",
    "*In addition, this combination of short-time static characterisation of the spectrum within a state and  the dynamics of change across states is rather elegant because the measure of equation (8) can be decomposed simply into a summation of the joint probability of O, the observation, and q, the state sequence, as defined by equation (7).  The decomposition permits independent study and analysis of the behaviour of the short-time processes and the long-term characteristic transitions.  Since decoding and recogntion are our main concenrs, this also procides an intermediate level of decision that can be used to choose among alternate configurations of the models for the recognition task.  This kind of flexibility with consistency is particularly useful for converting a time-varying signal such as speech, without clear anchor points that mark each sound change, into a sequence of (sound) codes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training algorithm\n",
    "*\n",
    "Another attractive feature of HMM's comes from the fact that it is relatively easy and straight forward to train a model from a given set of labeled training data (one or more sequences of observations).\n",
    "*\n",
    "\n",
    "*\n",
    "When the ML criterion is chosen as the estimation objective - that is , maximisation of $Pr(O|\\lambda)$ over $\\lambda$ - the well-known Baum-Welch algorithm is an iterative hill-climbing prosidure that leads to, at least, a fixed-point solution as explained earlier.  If we choose the stat-optimized (or decoded) likelihood defined by\n",
    "*\n",
    "$$L_\\lambda(\\bar{q})=max_qPr(O,q|\\lambda), - - - - \\dots(17)$$\n",
    "*where*\n",
    "$$\\bar{q}=arg max_qPr(O,q|\\lambda), - - - - \\dots(18)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*as the optimization criterion, the segmental k-means algorithm which is an extended version of the Viterbi training/segmentation algorithm can be conviniently used to accomplish this parameter training task.\n",
    "*\n",
    "\n",
    "*\n",
    "The segmental k-means algorithm as can be seen from the objective function of equation (17), involves two optimization steps - namely, the segmentation step and the optimization step.  In the segmentation step, we find a state sequence $\\bar{q}$ such at equation (17) is obtained for a given model $\\lambda$ and observation sequence O.  Then, given a state sequence $\\bar{q}$ and the observation O, the optimization step finds a new set of model parameters $\\bar{\\lambda}$ so as to maximize equation (17): that is,*\n",
    "$$\\bar{\\lambda}=arg max_\\lambda\\{max_qPr(O,q|\\lambda)\\} - - - -\\dots(19)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Equation (19) can be rewritten as*\n",
    "$$\\bar{\\lambda}=arg max_\\lambda\\{max_q[log Pr(O|q,\\lambda)+log Pr(q|\\lambda)]\\} - - -\\dots(20)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that $max_\\lambda[log Pr(O|\\lambda)+log Pr(\\bar{q}|\\lambda)]$ consists of two terms that can be separately optimized since $log Pr(\\bar{q}|\\lambda)$ is a function of only A, the state transition probability matrix, and $log Pr(O|\\bar{q},\\lambda)$ is a function of only B, the family of (intrastate) observation distributions. (We neglect the initial state probability for simplicity in presentation.)  This separate optimization is the main distinction between the Baum-Welch algorithm and the segmental k-means algorithm.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*These two training algorithms both result in well-formulated and well-behaved solutions.  The segmental k-means algorithm, however, due to the separate optimization of the components of the model parameter set, leads to a more straightforward (simpler with less computation and numerical difficulties) implementation.*\n",
    "\n",
    "*The ease of HMM training also extends to choice of distributions.  It is known that these algorithms can accommodate observation densities that are (a) strictly log-concave densities (b) elliptically symetric densities, (c) mixtures of distributions of the preceeding two categories, and (d) discrete distributions.  These choices of observation distribution in each state and the model allow accurate modeling of virtually unlimited types of data.*\n",
    "\n",
    "### Modeling Flexibility\n",
    "\n",
    "*The flexibility of the basic HMM is manifested in three aspects of the model, namely; model topology, observation distributions, and decoding hierarchy.*\n",
    "\n",
    "*Many topological structures for HMM's have been studied for speech modeling.  For modeling isolated utterances (i.e. whole words or phrases), we often use left-to-right models like that shown in figure 3 below, since the utterance begins and ends with at well-identified time instants (except the case of very noisy or corrupted speech) and the sequential behaviour of the speech is well represented byy a sequential HMM.  For other speech-modelling task the use of ergodic models are often more appropriate.  The choice of topological configuration and the number of states in the model is generally a reflectiono f the a priori knowledge of the particular speech source to be modeled and is not in any way related to the mathematical tractibility or implementational considerations.*\n",
    "\n",
    "![Figure 3](https://selene.hud.ac.uk/u1273400/images/seg_media/hmm3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It has previously been pointed out that the range of observation distributions that can be accommodated by well-developed training algorithms is rather large.  There are no real analytical problems that make the use of any other of this rather rich class of distributions impractical.  Since speech has been shown to display quite irregular probability distributions both in waveform and spectral parameters, one indeed needs the freedom to choose an appropriate distribution model that fits the observation well and yet is easy to obtain.*\n",
    "\n",
    "*In modelling spectral observations, we have found the use of mixture densities beneficial.  With $f_i(.)$ denoting the kernal density function, the mixture density assumes the form*\n",
    "$$b(O)=\\sum_{i=1}^Mc_if_i(O) - - - -\\dots(21)$$\n",
    "*where $c_i$ is the mixture component weight, $\\sum_{i=1}^Mc_i=1$, and M is the number of mixture components.  This mixture distribution function is used to characterise the distribution of the observations in each state.  By varying the number of mixture components, M, it can be shown that it is possible to approximate densities of virtually any shape (unimodal, multimodal, heavy-tail, etc).*\n",
    "\n",
    "*With specific constraints, the basic form of the mixture distrution of equation (21) can be modified to accommodate several other types of distributions, giving rise to the so-called vector quantizer HMM, semicontinuous HMM or continuous HMM.*\n",
    "\n",
    "*The choice of observation distributions also extends to the ease of the HMM itself.  One can form an HMM with each state characterized by another HMM; that is, $b_i(O)$ of each state (i=1,2,...,N) can assume the form of an HMM probability measure as defined by equation (8).  This principle is the basis of many of the subword unit-based speech recognition algorithms.*\n",
    "\n",
    "### Ease of Implementation\n",
    "*\n",
    "Two areas of concern in the implementation of any algorithm are the potential for numerical difficulties and the computational complexity.  HMM is no exception*.  \n",
    "\n",
    "*The potential numerical difficulties in implementing HMM systems come from the fact that the terms in HMM probability measure of equations (7) and (8) are mltiplicative.  A direct outcome of the multiplicative chain is the need for excessive dynamic range in numerical values to prevent overflow problems in digital implementations.*\n",
    "\n",
    "*Numerical scaling and interpolation are two reasonable ways of avoiding such numerical problems.  The scaling algorithm, alleviates the dynamic range problem by normalising the partial probabilities, such as the forward variable previously defined at each time instance before they cause overflow or underflow.  The scaling algorithm is naturally blended in the forward-backward procedure.  Normalisation alone, however, does not entirely solve the numeric problems that result from insufficient data support.  Insufficient data support can cause spuriious singlularities in the model parameter space.  One may resort to parameter smoothing and interpolation to alleviate such numerical singularity problems.  A particularly interesting method to deal with sparse data problems is the scheme of deleted interpolation.  For HMM speech recognition, some trivial measures such as setting a numeric floor to prevent singularity are often found beneficial and are straightforward to implement.*\n",
    "\n",
    "*With the understanding of the relationship between the trellis structure and the decoding structure of the HMM, as discussed in the evaluation problem,  we are able to apply the HMM to many complicated problems without much concern to computational complexity.  A simple calculation could verify that a typical off-the shelf digital signal processor of 10 million floating point operations per second woud be able to support a 100-word recognition vocabulary for a real-time performance.  Ven as recognition vocabularies increase to size 1,000 or more, the required processing often remains pretty much the same because of grammatical constrains that limit the average number of words following a given word to somewhere on the order of 100 words. This effect is called word-average branching factor or perplexity and has been shown to be on the order of 100 for several large vocabulary recognition tasks.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Baum, L. E. (1972). An equality and associated maximization technique in statistical estimation for probabilistic functions of Markov processes. Inequalities, 3, 1-8.\n",
    "\n",
    "Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete data via the EM algorithm. Journal of the royal statistical society. Series B (methodological), 1-38.\n",
    "\n",
    "Ferguson, J. D. (1980, October). Hidden Markov analysis: an introduction. In Proceedings of the Symposium on the Applications of Hidden Markov Models to Text and Speech, IDA-CRD, Princeton, NJ.\n",
    "\n",
    "Rabiner, L., & Juang, B.-H. (1993). Fundamentals of speech recognition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
