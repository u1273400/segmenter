{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Calculus\n",
    "\n",
    "### Introduction\n",
    "In this section we discuss the concept of conditional time dependence component.  In order to model randomness in signals (noise signals), we introduce the notion of random processes.  Note that the tools are deterministic mathematical constructs; randomness only enters when observations are conducted.  We first state the clasic definition of random processes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Definition 1.  Random Processes\n",
    "*A random (or stochastic) process $\\{X_t,t\\in T\\}$ is a collection of random variables on the same probability space $(\\Omega, \\mathcal{F},P)$.  The index set T is usually representing time and can be either an interval [t<sub>1</sub>,t<sub>1</sub>] or a discrete set.  Therefore the random process X can be written as a function:*\n",
    "$$ X : \\mathbb{R} \\times \\Omega \\rightarrow \\mathbb{R}, (t,\\omega) \\mapsto X(t,\\omega) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*In the stochastic interpretation, a sample $\\omega$ is chosen from the sample space $\\Omega$ \"at random\".  This yields the \"stochatic signal\" or \"noise signal\" r(.,$\\omega$) defined on index set T.  This signal is also denoted as sample path, realisation or trajectory.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notation Remark\n",
    "We introduced random or stochastic processes as functions wth to arguments: t and $\\omega$.  We will, however, omit the argument $\\omega$ for brevity as it is done in most text books: X(t,$\\omega$)=X(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By the definition of random processes, we know that the amount of information is increasing with time.  Again, we need the concept of sigma algebras.  We assume that information is not lost with increasing time and therefore the corresponding $\\sigma$-algebras will increase over time as more and more information becomes available. This concept is called filtration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition 2 Filtration/adapted process\n",
    "A collection $\\{\\mathcal{F}_t\\}_{t\\ge0}$ of a sub $\\sigma$ algebras is called filtration if, for every $s\\le t$ we have $\\mathcal{F}_s\\subseteq\\mathcal{F}_t$.  The random variables $\\{X_t:0\\le t\\le\\infty\\}$ are called adpated to the filtration $\\mathcal{F}_t$ if, for every t, X<sub>t</sub> is meaurable with respect to $\\mathcal{F}_t$.\n",
    "![Figure 1](https://selene.hud.ac.uk/u1273400/images/seg_media/r1.PNG)\n",
    "**Figure 1** Example of a filtration\n",
    "\n",
    "The concept of a filtration is easily understood with a simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1\n",
    "Suppose we have a sample space of four elements: $\\Omega=\\{\\omega_1, \\omega_2, \\omega_3, \\omega_4\\}$.  At time zero, we do not have any information about which $\\omega$ has been chosen.  At time T/2 we know whether we have $\\Omega=\\{\\omega_1, \\omega_2\\}$ or $\\{\\omega_3, \\omega_4\\}$. At time T, we have full information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we have the folloing $\\sigma$-algebras:\n",
    "$$ \\mathcal{F}_t=\\left\\{\n",
    "\\begin{aligned}[lcr]\n",
    "\\{0,\\Omega\\}, && t \\in [0, \\frac{T}{2}) \\\\\n",
    "\\{0,\\{\\omega_1,\\omega_2\\},\\{\\omega_3,\\omega_4\\},\\Omega\\}, && t \\in [\\frac{T}{2}, T) \\\\\n",
    "\\mathcal{F}_{max}=2^{\\Omega}, && t=T\n",
    "\\end{aligned} \\right\\} $$\n",
    "\n",
    "Thus $\\mathcal{F}_0$ represents initial information whereas  $\\mathcal{F}_\\infty$ represents full information (all we will ever know).  Therefore, a stochastic process is said to to be defined on a filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_t\\}_{t \\ge 0},P)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going into the topics of random processes, stationary random processes, Gaussian random processes, etc. let us first recapitulate two (almost) trivial properties of deterministic functions:\n",
    "\n",
    "Let x(.) be a real, continuously differentiable function defined on the interval [0,T].  Its continuously differentiability implies both a bounded total variation and a vanishing \"sum of squared increments\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. Total variation: $$ \\int_0^T\\left|\\frac{dx(t)}{dt}\\right|dt<\\infty$$\n",
    "2. Sum of squares:$$\\lim_{N\\rightarrow\\infty}\\sum_{k=1}^N\\left[x\\left(k\\frac{T}{N}\\right)-x\\left((k-1)\\frac{T}{N}\\right)\\right]^2=0$$\n",
    "\n",
    "Random processes do not have either of these nice smoothness properties in general.  This allows the desired \"wild\" and \"random\" behaviour of the (sample) \"noise signals\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes of Processes\n",
    "\n",
    "#### Markov Process\n",
    "\n",
    "A Markov Process X is a particular type of stochastic processes where only the present value X(t) is relevant for predicting the future evolution of X.  Therefore, the past and the future of a Markov process have no direct interconnection.  More formally we have:\n",
    "\n",
    "#### Definition 3: Markov Process\n",
    "A continuous-time stochastic process X(t),$t \\in T$, is called a Markov process if for any finite parameter set $\\{t_i:t_i<t_{i+1}\\}\\in T$ we have\n",
    "$$P(X(t_{n+1})\\in B|X(t_1),\\dots,X(t_n))=P(X(t_{n+1}\\in B|X(t_n))$$\n",
    "\n",
    "For a markov process X(t) we define the transition probability, denoted by P(s,x,t,B) as follows:\n",
    "$$ P(s,x,t,B)=P(X(t)\\in B|X(s)=x), 0\\le s\\le t $$\n",
    "\n",
    "The function P gives the probability of X(t) lying in the set B at time t, given the value x of the process at time s.  The transition density p is implicitly defined as \n",
    "$$ P(s,x,t,B)=\\int_B{p(s,x,t,y)dy} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Process\n",
    "\n",
    "A stochastic process is called Gaussian if all of its joint probability distributions are Gaussians.  If X(t) is a Gaussian process then $X(t)~\\mathcal{N}(\\mu(t),\\sigma^2(t))$ for all t, where $\\mu(t)$ and $\\sigma^2(t)$ are arbitrary functions.  A Gaussian process is fully characterised by its mean covariance function.  Gaussian processes do have many nice mathematical properties.  For example performing linear algebraic operations on a Gaussian process yields a Gaussian process.  Another important property is that the limit of a Gaussian random sequence remains a Gaussian process.  Hence, the mean square derivatives and integrals of Gaussian processes themselves.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Martingales\n",
    "\n",
    "A stochastic process X(t) is a martingale on the filtered probability space $(\\Omega,\\mathcal{F},\\{\\mathcal{F}_t\\}_{t\\ge 0},P)$ if the following conditions hold:\n",
    "- X(t) is $\\{\\mathcal{F}_t\\}_{t\\ge 0}-\\text{adapted, }E||X(t)||< \\infty\\text{ for all }t\\ge 0$\n",
    "- $E[X(t)|\\mathcal{F}_s]=X(s)$ a.s. for all $s \\in [0,t]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From this definition, it follows that the best prediction of a martingale process is its current value.  We therefore state that martingale processes model fair games.  If we consider a coin tossing game where the player gains one dollar on head and loses one dollar on tail the wealth of the player follows a martingale. The martingale theory is a fundamental tool in finance, and the theory it is vast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DIffusions\n",
    "\n",
    "A diffusion is a Markov process with continuous trajectories such that for each time t and state X(t) the following limits exist.\n",
    "$$\\mu(t,X(t)):=\\lim_{\\Delta\\downarrow 0}\\frac{1}{\\Delta t}E[X(t+\\Delta t)-X(t)|X(t)],$$\n",
    "$$\\sigma^2(t,X(t)):=\\lim_{\\Delta\\downarrow 0}\\frac{1}{\\Delta t}E[\\{X(t+\\Delta t)-X(t)\\}^2|X(t)]$$\n",
    "For these limits,$\\mu(t,X(t))$ is called drift and $\\sigma^2(t,X(t))$ is called the diffusion coefficient.  Since diffusion are Markov processes we expect a relationship between the transition probability and  $\\mu(t,X(t))$,  $\\sigma^2(t,X(t))$.  Actually, under certain assumptions, the transition probability is uniquely determined by $\\mu(t,X(t))$ and $\\sigma^2(t,X(t))$.  This is a pretty surprising result because usually distribtioni s not completely determined by its first two moments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brownian Motion and White Noise\n",
    "\n",
    "#### Brownian Motion\n",
    "\n",
    "Motivated by the apparently random walk of a tiny particle in a fluid (observed by the Scottish botanist Robert Brownian in 1827), the American mathematician Norbert Wiener stipulated the following assumptions for a stationary random process W(-,-) with independents in 1923:\n",
    "\n",
    "#### Definition 2.6: Brownian Motion\n",
    "A stochastic process W(t) is called Brownian motion if\n",
    "1. Independence: $W(t+\\Delta t)-W(t)$ is independent of $\\{W(\\tau)\\}$ for all $\\tau\\le t$.\n",
    "2. Stationarity: The distribution of $W(t+\\Delta t) - W(t)$ does not depend on t.\n",
    "3. Continuity: $lim_{\\Delta\\downarrow 0}\\frac{P(|W(t+\\Delta t)-W(t)|\\ge \\delta)}{\\Delta t}=0 \\text{ for all } \\delta > 0$.\n",
    "\n",
    "Please note that the third assumption is expressed with probabilities: discontinuities in sample functions can only occur with probability zero.  Hence, there is a version of the Brownian motion with all sample functions continuous. (This technically is not of any practical importance.)\n",
    "\n",
    "This definition induces the distribution of the process $W_t$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Theorem 2.7 Normally distributed increments of Brownian motion \n",
    "Normally distributed increments of Brownian motion with mean $\\mu t$ and variance $\\sigma^2t$, where $\\mu$ and $\\sigma$ are constant real numbers.\n",
    "\n",
    "As a result of this theorem, we have the following density function of a Brownian motion:\n",
    "$$ f_{W(t)}(x)=\\frac{1}{\\sqrt{2\\pi\\sigma^2t}}e^\\frac{(x-\\mu t)^2}{2\\sigma^2 t}$$\n",
    "\n",
    "An irritating property of Brownian motion is that its sample paths are not differentiable.  This is easily verified in the mean-square sence:\n",
    "$$E\\left[\\left(\\frac{W(t+\\Delta t)-W(t)}{\\Delta t}\\right)^2\\right]=\n",
    "\\frac{E[(W(t+\\Delta t)-W(t))^2]}{\\Delta t^2}=\\frac{\\sigma^2}{\\Delta t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This diverges for $\\Delta t\\rightarrow 0$ and therefore it is not differentiable in $L^2$.  This is also the case for almost sure convergence, but this is much mnore difficult to prove.\n",
    "\n",
    "The brownian motion has many bizarre and intriguing properties.  Some of them are listed below:\n",
    "\n",
    "- Autocovariance function: $E{(W(t)-\\mut)(W(\\tau)-\\mu\\tau)}=\\sigma^2min(t,\\tau)$.\n",
    "- $Var\\left\\{\\frac{W(t)}{t}\\right\\}=\\frac{\\sigma^2}{t}$\n",
    "- $\\lim_{t\\rightarrow\\infty}\\frac{W(t)-\\mu t}{t}=0$ with probability 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
